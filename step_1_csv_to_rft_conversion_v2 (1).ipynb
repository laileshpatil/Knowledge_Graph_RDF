{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76499db2-9a1c-4c77-b994-7993009ca667",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: rdflib in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (7.0.0)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (1.35.2)\n",
      "Requirement already satisfied: SPARQLWrapper in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: iribaker in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (0.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from rdflib) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from rdflib) (3.1.4)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.2 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from boto3) (1.35.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from boto3) (0.10.2)\n",
      "Requirement already satisfied: rfc3987 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from iribaker) (1.3.8)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from botocore<1.36.0,>=1.35.2->boto3) (2.2.2)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages (from isodate<0.7.0,>=0.6.0->rdflib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas rdflib boto3 SPARQLWrapper iribaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d4f3d26-3f47-422b-a582-7027b67ec963",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (404) when calling the HeadObject operation: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m file_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_raw.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m local_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_recon_mismatch.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[43ms3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from S3 bucket \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages/boto3/s3/inject.py:192\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Download an S3 object to a file.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03mUsage::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m    transfer.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages/boto3/s3/transfer.py:406\u001b[0m, in \u001b[0;36mS3Transfer.download_file\u001b[0;34m(self, bucket, key, filename, extra_args, callback)\u001b[0m\n\u001b[1;32m    402\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mdownload(\n\u001b[1;32m    403\u001b[0m     bucket, key, filename, extra_args, subscribers\n\u001b[1;32m    404\u001b[0m )\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# This is for backwards compatibility where when retries are\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# exceeded we need to throw the same error from boto3 instead of\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# s3transfer's built in RetriesExceededError as current users are\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# catching the boto3 one instead of the s3transfer exception to do\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# their own retries.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3TransferRetriesExceededError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages/s3transfer/futures.py:103\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coordinator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages/s3transfer/futures.py:266\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# final result.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages/s3transfer/tasks.py:269\u001b[0m, in \u001b[0;36mSubmissionTask._main\u001b[0;34m(self, transfer_future, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_coordinator\u001b[38;5;241m.\u001b[39mset_status_to_running()\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# Call the submit method to start submitting tasks to execute the\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;66;03m# transfer.\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_submit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransfer_future\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransfer_future\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# If there was an exception raised during the submission of task\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# there is a chance that the final task that signals if a transfer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# Set the exception, that caused the process to fail.\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_and_set_exception(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages/s3transfer/download.py:354\u001b[0m, in \u001b[0;36mDownloadSubmissionTask._submit\u001b[0;34m(self, client, config, osutil, request_executor, io_executor, transfer_future, bandwidth_limiter)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m:param client: The client associated with the transfer manager\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m    downloading streams\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transfer_future\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39msize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;66;03m# If a size was not provided figure out the size for the\u001b[39;00m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;66;03m# user.\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransfer_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransfer_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtransfer_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m     transfer_future\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mprovide_transfer_size(\n\u001b[1;32m    360\u001b[0m         response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContentLength\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    361\u001b[0m     )\n\u001b[1;32m    363\u001b[0m download_output_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_download_output_manager_cls(\n\u001b[1;32m    364\u001b[0m     transfer_future, osutil\n\u001b[1;32m    365\u001b[0m )(osutil, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_coordinator, io_executor)\n",
      "File \u001b[0;32m~/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages/botocore/client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/JupyterSystemEnv/lib/python3.10/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (404) when calling the HeadObject operation: Not Found"
     ]
    }
   ],
   "source": [
    "#downlaoding source file name file from S3 local dir\n",
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'dev-input'\n",
    "file_key = 'input_raw.csv'\n",
    "local_file_path = 'tf_recon_mismatch.csv'\n",
    "\n",
    "s3.download_file(bucket_name, file_key, local_file_path)\n",
    "print(f\"Downloaded {file_key} from S3 bucket {bucket_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62db88b2-b2b9-4f22-a46e-ac7fbb7b89ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_file_path = 'tf_recon_mismatch.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c35f98f7-caf2-47af-804b-15653d1dfd05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rdflib\n",
    "from rdflib import Graph as RDFGraph\n",
    "import csv\n",
    "from rdflib import Dataset, URIRef, Literal, Namespace, RDF, RDFS, OWL, XSD, BNode, FOAF, SDO\n",
    "from iribaker import to_iri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc0f0e-f37a-409c-bfa6-68e0ab000374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an empty RDF graph\n",
    "g = rdflib.Graph(bind_namespaces=\"core\")\n",
    "\n",
    "#create namespace\n",
    "ex = Namespace(\"http://example.com/rtf/\")\n",
    "\n",
    "#bind prefix to neamespace\n",
    "g.bind('', ex)\n",
    "#g.bind(\"foaf\", FOAF)\n",
    "g.bind('schema', SDO)\n",
    "\n",
    "node_subject = 'alm_bsm_contract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419c96e-02c7-47ac-8c2f-25b5985c1de3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_and_load_csv_to_rdf(csv_file_path):\n",
    "    with open(csv_file_path, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        headers = reader.fieldnames\n",
    "        #print(headers)\n",
    "\n",
    "        for row in reader:\n",
    "\n",
    "            #mismatch\n",
    "            mismatch_field = row['MISMATCHED_FIELD']\n",
    "            mismatch = URIRef(ex[mismatch_field])        \n",
    "            \n",
    "            #split tableName and column name\n",
    "            mismatch_fields = (mismatch_field.split(\".\"))\n",
    "            table_name = mismatch_fields[0]\n",
    "            column_name = mismatch_fields[1]\n",
    "                       \n",
    "            #add column type\n",
    "            column = URIRef(ex[column_name]) \n",
    "            g.add((column, RDF.type, ex.column))\n",
    "            g.add((column, ex['name'], (Literal(column_name, datatype=rdflib.XSD.string))))            \n",
    "            \n",
    "            #add table type\n",
    "            table = URIRef(ex[table_name]) \n",
    "            g.add((table, RDF.type, ex.table))\n",
    "            g.add((table, ex['name'], (Literal(table_name, datatype=rdflib.XSD.string)))) \n",
    "            \n",
    "            #table column to table\n",
    "            g.add((table, ex.hasColumn, column))\n",
    "        \n",
    "            #add table to mismatch\n",
    "            g.add((mismatch, RDF.type, ex.mismatch))\n",
    "            g.add((mismatch, ex.hasTable, table))\n",
    "\n",
    "            property_value = Literal(row['BASELINE_VALUE'], datatype=rdflib.XSD.string)\n",
    "            g.add((mismatch, ex['baseline_value'], property_value))\n",
    "\n",
    "            property_value = Literal(row['ENHANCED_VALUE'], datatype=rdflib.XSD.string)\n",
    "            g.add((mismatch, ex['enhanced_value'], property_value))\n",
    "\n",
    "            #discrepancy\n",
    "            compare_key_value = row['COMPARE_KEY_VALUE']\n",
    "            discrepancy_compare = URIRef(ex[compare_key_value])\n",
    "            g.add((discrepancy_compare, RDF.type, ex.discrepancy)) \n",
    "            g.add((discrepancy_compare, ex['compare_key_value'], (Literal(compare_key_value, datatype=rdflib.XSD.string)))) \n",
    "\n",
    "            #add mismatch to discrepancy\n",
    "            g.add((discrepancy_compare, ex.hasMismatch, mismatch))\n",
    "\n",
    "            #creating node for Application Run\n",
    "            run_id = row['RUN_ID']\n",
    "            application_run = URIRef(ex[run_id])\n",
    "            g.add((application_run, RDF.type, ex['application_run']))\n",
    "            g.add((application_run, ex['run_id'], (Literal(run_id, datatype=rdflib.XSD.string))))\n",
    "\n",
    "            #adding business date property\n",
    "            property_value = Literal(row['BUSINESS_DATE'], datatype=rdflib.XSD.date)\n",
    "            g.add((application_run, ex['business_date'], property_value))\n",
    "\n",
    "            property_value = Literal(row['STRM_IDNN'], datatype=rdflib.XSD.string)\n",
    "            g.add((application_run, ex['strm_idnn'], property_value))\n",
    "\n",
    "            #add discrepancy to application\n",
    "            g.add((application_run, ex.hasDiscrepancy, discrepancy_compare))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f66f67-b1f2-4128-ab17-de2eac793b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parse_and_load_csv_to_rdf(local_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71652927-b999-45a2-8358-3d7ba7b3f81a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(g.serialize(format='ttl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6520e5d5-294d-4698-9149-e1726f6c4ff4",
   "metadata": {},
   "source": [
    "validation of what loaded in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f6ac8876-1ad2-43dd-ae4d-b4ec13db28fe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('brick', rdflib.term.URIRef('https://brickschema.org/schema/Brick#'))\n",
      "('csvw', rdflib.term.URIRef('http://www.w3.org/ns/csvw#'))\n",
      "('dc', rdflib.term.URIRef('http://purl.org/dc/elements/1.1/'))\n",
      "('dcat', rdflib.term.URIRef('http://www.w3.org/ns/dcat#'))\n",
      "('dcmitype', rdflib.term.URIRef('http://purl.org/dc/dcmitype/'))\n",
      "('dcterms', rdflib.term.URIRef('http://purl.org/dc/terms/'))\n",
      "('dcam', rdflib.term.URIRef('http://purl.org/dc/dcam/'))\n",
      "('doap', rdflib.term.URIRef('http://usefulinc.com/ns/doap#'))\n",
      "('foaf', rdflib.term.URIRef('http://xmlns.com/foaf/0.1/'))\n",
      "('geo', rdflib.term.URIRef('http://www.opengis.net/ont/geosparql#'))\n",
      "('odrl', rdflib.term.URIRef('http://www.w3.org/ns/odrl/2/'))\n",
      "('org', rdflib.term.URIRef('http://www.w3.org/ns/org#'))\n",
      "('prof', rdflib.term.URIRef('http://www.w3.org/ns/dx/prof/'))\n",
      "('prov', rdflib.term.URIRef('http://www.w3.org/ns/prov#'))\n",
      "('qb', rdflib.term.URIRef('http://purl.org/linked-data/cube#'))\n",
      "('schema', rdflib.term.URIRef('https://schema.org/'))\n",
      "('sh', rdflib.term.URIRef('http://www.w3.org/ns/shacl#'))\n",
      "('skos', rdflib.term.URIRef('http://www.w3.org/2004/02/skos/core#'))\n",
      "('sosa', rdflib.term.URIRef('http://www.w3.org/ns/sosa/'))\n",
      "('ssn', rdflib.term.URIRef('http://www.w3.org/ns/ssn/'))\n",
      "('time', rdflib.term.URIRef('http://www.w3.org/2006/time#'))\n",
      "('vann', rdflib.term.URIRef('http://purl.org/vocab/vann/'))\n",
      "('void', rdflib.term.URIRef('http://rdfs.org/ns/void#'))\n",
      "('wgs', rdflib.term.URIRef('https://www.w3.org/2003/01/geo/wgs84_pos#'))\n",
      "('owl', rdflib.term.URIRef('http://www.w3.org/2002/07/owl#'))\n",
      "('rdf', rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#'))\n",
      "('rdfs', rdflib.term.URIRef('http://www.w3.org/2000/01/rdf-schema#'))\n",
      "('xsd', rdflib.term.URIRef('http://www.w3.org/2001/XMLSchema#'))\n",
      "('xml', rdflib.term.URIRef('http://www.w3.org/XML/1998/namespace'))\n",
      "('ex', rdflib.term.URIRef('http://example.com/rft/'))\n"
     ]
    }
   ],
   "source": [
    "for prefix,ns in g.namespaces():\n",
    "    print((prefix, ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762336ed-223c-43c2-aabf-4f33946ebf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the node values.\n",
    "#g.set(s, p, o)\n",
    "#g.remove(s,p, o)\n",
    "#.g.remove(s,none, none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a6b4cb76-d336-4afb-9745-00fe7b47c172",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDF data saved output7.ttl successfully.\n"
     ]
    }
   ],
   "source": [
    "#Serialize the RDF graph to a file \n",
    "output_file = 'output7.ttl'\n",
    "fmt = 'ttl'\n",
    "g.serialize(destination=output_file, format=fmt)\n",
    "print(f\"RDF data saved {output_file} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7e21ae7d-5841-4760-b255-29076bb48d18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1523"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf_data = g.serialize(fromat='ttl')\n",
    "len(rdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "00614275-91e5-422c-998c-c3114fb4c7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to execute SPARQL update\n",
    "def push_triples_to_neptune(sparql_endpoint, query):\n",
    "    sparql = SPARQLWrapper(sparql_endpoint)\n",
    "    sparql.setMethod(POST)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    sparql.addParameter(\"Accept\", \"application/sparql-results+json\")\n",
    "    try:\n",
    "        response = sparql.query().convert()\n",
    "        print(\"Data pushed successfully:\", response)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to push data:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1d3d955a-660d-4a7f-8cb0-442ba24ab598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from SPARQLWrapper import SPARQLWrapper, POST, JSON\n",
    "# AWS Neptune configuration\n",
    "neptune_endpoint = \"db-neptune-1.cluster-cfaicgyug7jh.ap-southeast-2.neptune.amazonaws.com\"\n",
    "neptune_port = \"8182\"  # default port for Neptune\n",
    "neptune_region = \"ap-southeast-2\"\n",
    "\n",
    "# SPARQL endpoint\n",
    "sparql_endpoint = f\"https://{neptune_endpoint}:{neptune_port}/sparql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "dbc6788c-5e11-4a64-9621-1c25370e84f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SPARQL Update query to insert data\n",
    "rdf_data = g.serialize(fromat='ttl')\n",
    "sparql_insert_query = \"\"\"\n",
    "    INSERT DATA { \n",
    "            \"\"\" + rdf_data + \"\"\"\n",
    "        }\n",
    "\"\"\"\n",
    "#print(sparql_insert_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a5dff8fd-0503-4e51-99f8-ddb41b8c3487",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to push data: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Push triples to AWS Neptune\n",
    "push_triples_to_neptune(sparql_endpoint, sparql_insert_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85192e4-fce3-446f-93bc-d9c5277737d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload RDF/ttl file to S3 to load by Bulk loader\n",
    "\n",
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket_name = 'dev-input'\n",
    "file_key = 'output.ttl'\n",
    "output_file_name = 'output.ttl'\n",
    "\n",
    "s3.upload_file(output_file_name, bucket_name, file_key)\n",
    "print(f\"uploaded {file_key} file to S3 bucket {bucket_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14418b2-3880-4059-a492-c50a14ca33ba",
   "metadata": {},
   "source": [
    "<h3> varifying if data is pushed to Neptune DB </h3>\n",
    "sometime error shown as Failed to push data. to be invested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "08ee590e-a64b-4f29-b694-138497cde13e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96047a03761046b68502e90fcf1db5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(layout=Layout(max_height='600px', max_width='940px', overflow='scroll')), Force(network=<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sparql\n",
    "SELECT ?s ?p ?o WHERE {?s ?p ?o} LIMIT 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a3b33fb9-c3d0-47e6-8244-bcf23858ec6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785a5b58eb704c4daba90e458f05d58d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(layout=Layout(max_height='600px', max_width='940px', overflow='scroll')), Output(layout=L…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sparql\n",
    "CLEAR ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd8846-2d39-41f2-a163-e915eaa03d25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
